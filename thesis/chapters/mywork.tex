\chapter{基于卷积神经网络的影评分类实验}
\section{数据集与预处理}
\subsection{数据的获取与概况}
本课题采用的数据集是来自豆瓣的中文影评数据。使用微软必应（Bing）搜索的Cosmos分布式处理平台获取。来自Cosmos的数据是原始的HTML 文本，使用HtmlAgility库对其进行解析，提取出有用的影评、评分等信息，整理成JSON格式的文件。数据的基本信息如\ref{tab:comment count}所示。

\begin{table}
\centering
\caption{短评数据数量表格} \label{tab:comment count}
\begin{tabular}{c|c|c|c}
    \hline
    全部短评数量 & 全部长评数量 & 短评来源用户数量 & 短评对应电影数量\\
    \hline
    124591 & 100000 & 42517 & 4887\\
    \hline
\end{tabular}
\end{table}

整理生成的短评数据示例如\ref{tab:comment format}所示。
\begin{table}
\centering
\caption{短评数据示例} \label{tab:comment format}
\begin{tabular}{c|c|c|c|c|c|c}
    \hline
    Text & Username & Rate & Cid & Vote & MovieName & MovieId\\
    \hline
    这么高分我有点不懂 & X.Lee & 3 & 1005243594 & 12 & 拿起枪的简 & 10760385\\
    \hline
\end{tabular}
\note{整理后的短评JSON数据示例。长评数据格式与之类似，但多了Title域}
\end{table}

短评数据每条的长度不超过140个字符，每条都带有对应评分（1到5星）；长评数据没有字数限制，同样每条都包括1到5星的评分。

选择来自豆瓣的中文影评作为语料的优势在于，短评和长评都可以看作有标注的数据，这就意味着我们不再需要再人工地对数据进行标注就可以在它们上面进行有监督的学习。此外，豆瓣的短评有长度的限制，易于转换为固定大小的输入矩阵，故我们使用短评作为主要的实验数据。对于获取到的长评数据，虽然它们也是有标注的数据，但由于它们之间长度相差很大，而且相对于情感信息比较密集的短评，长评中可能有很多谈论具体电影情节的，不带情感色差的内容。所以本课题不直接使用长评数据进行实验，而是使用他们进行了词嵌入的训练。因为长评数据本身的数据量很大，其语境和用语习惯与短评非常接近，所以使用它们作为训练词嵌入的语料非常适合。

\subsection{分词与训练词嵌入}
获得了JSON格式的数据后，由于JSON中的Text域是原始的短评文本，所以还需要进行分词和训练词嵌入才能将这些数据转化为神经网络可以接受的形式。本课题采用的中文分词工具是斯坦福大学自然语言处理研究组的Stanford Word Segmenter，该分词工具基于的算法是使用条件随机场（Conditional Random Field）去做sequence model。

将短评数据和长评数据进行分词后，将其作为输入数据进行词嵌入的训练。训练词嵌入采用的算法是基于Continuous Bag of Word的Word2vec，这是一种高效率的词嵌入训练算法。本课题使用gensim库中对Word2vec的实现，选取词向量长度为100，从短评和长评数据中训练出了中文词语的词词嵌入。

\subsection{实验设置}
本课题的实验分为两种，第一种是由中文电影短评预测该短评对应的评分（1到5星），本课题以短文本五分类的方法来实现对影评的预测；第二种是将五分类的中的3星评论去除，以1星和二星评论作为负面评论，四星和五星评论作为正面评论，由短评的内容预测其评论的倾向（正面还是负面），将问题转化为个短文本二分类来做。

在使用短评数据进行实验之前，我对短评根据其作者发布的影评数量进行了筛选，只保留了发表影评数量超过5的较活跃用户的影评。符合要求的影评共67255篇。抽取其中60000篇，进行了shuffle后按\ref{tab:data divide}划分了训练集，验证集和测试集（由于第二类实验需要去除三星的评论，故第二类实验的数据规模与第一类有所区别）：

\begin{table}
\centering
\caption{实验数据划分表格} \label{tab:data divide}
\begin{tabular}{c|c|c|c}
    \hline
     &训练集 & 验证集 & 测试集\\
    \hline
    评分预测实验 & 40000 & 10000 & 10000\\
    \hline
    二分类实验 & 28204 & 7059 & 7016\\
    \hline
\end{tabular}
\end{table}



\section{不同的卷积神经网络结构}
\subsection{单层单通道}
结构如第三章中所述，只有一层卷积层，卷积的输出经过pooling和dropout直接传给最后进行分类的全连接Softmax只使用一个词嵌入，故卷积神经网络的输入的第三维宽度只有一，对应图像数据只有一个通道。这里的词嵌入层也作为神经网络的一部分，词向量的值也会通过backpropagation更新。

我们使用单层单通道网络在词语层面（使用中文分词器断句）和字层面（在每个字断句）的输入上都进行了实验，其中词语层面的词嵌入使用Word2vec的训练结果初始化，字层面则随机初始化。

\subsection{单层双通道}
同样只有一层卷积层，但有两个词嵌入，故传给卷积层的输入第三维大小为2，即有两个通道。这两个词嵌入都使用Word2vec的训练结果初始化，其差别在于只有其中一个在训练过程中保持更新，另一个则始终不变。单层双通道只在词语层面的输入上进行了实验。

\subsection{双层卷积神经网络}
使用两个卷积层，在字层面的输入上进行实验。旨在第一层完成字组合的特征提取，第二层提取更高层面的特征。

\section{Baseline 实验}
本课题进行了三个baseline实验用作对比和分析。分别为朴素贝叶斯分类器，基于Tf.idf特征抽取的支撑向量机，和LSTM神经网络。由于在本文的第二章文本情感分析已经对baseline方法的基本原理进行了介绍，这里只说明具体的实验设置。

朴素贝叶斯分类器使用基于计数的方法计算$P(w_i|C)$和$P(C)$。对于单词的出现次数设置阈值10，即一个单词只有在训练数据中出现的次数超过十次才能被用在预测中。具体的概率的计算方法和算法流程见算法\ref{Naive Bayes}。

支撑向量机使用Tf.idf来进行特征抽取，将句子转化为一个一维的向量。对于Tf.idf的词典设置阈值50，因为向量化的结果的长度等于词典大小，故需要选取一个比较高的阈值以压缩向量长度，选取50为阈值得到的向量长度约2000。使用RBF的核函数，Soft Margin的支撑向量机设置。对于评分预测的五分类的实验，使用one-agains-all的方法，将支撑向量机由二分类拓展为5分类。具体的算法流程见算法\ref{SVM}。

LSTM神经网络使用Tensorflow实现。输入数据为经过词嵌入的得到的词向量序列，单层的LSTM之后，经过一个平均值池化（mean-pooling），对每个词向量的输出取平均值，得到一个长度为隐藏层宽度（设定为128）的一维向量。该一维向量再通过一个Softmax，得到分类的预测结果。

\section{小结}
本章对本课题所做的工作进行了说明。首先说明了数据的来源，对数据的预处理，已经实验的总体设置；然后说明了实现的不同神经网络结构的区别；之后，说明了baseline实验的设置。
